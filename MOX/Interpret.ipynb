{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kpt/.pyenv/versions/kedro19/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import LayerConductance\n",
    "from captum.attr import NeuronConductance\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update path to dataset here.\n",
    "dataset_path = \"aligned_df.pq\"\n",
    "data_set = pd.read_parquet(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Hyper-parameters \n",
    "\n",
    "num_classes = 1\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "\n",
    "\n",
    "# input_size = 5\n",
    "sequence_length = 100 # the window it trains with can be selected\n",
    "hidden_size = 32\n",
    "# hidden_size = 256 \n",
    "num_layers = 2\n",
    "step_size = 1\n",
    "\n",
    "# features = ['timestamp', 'A1_Sensor', 'A1_Sensor_diff', 'A1_Resistance', 'A1_Resistance_diff', 'A1_Sensor_norm', 'A1_Resistance_norm']\n",
    "features = ['timestamp_bin', 'A1_Resistance', 'A1_Resistance_diff', 'A1_Resistance_norm']\n",
    "target_column = 'resistance_ratio'\n",
    "\n",
    "input_size = len(features)  # Number of features\n",
    "\n",
    "# create sequences for each experiment\n",
    "# sequence_length = 50  # Example sequence length\n",
    "\n",
    "# features = ['timestamp', 'A1_Sensor', 'A1_Sensor_diff', 'A1_Resistance', 'A1_Resistance_diff', 'A1_Sensor_norm', 'A1_Resistance_norm']\n",
    "features = ['timestamp_bin', 'A1_Resistance', 'A1_Resistance_diff', 'A1_Resistance_norm']\n",
    "target_column = 'resistance_ratio'\n",
    "\n",
    "input_size = len(features)  # Number of features\n",
    "\n",
    "# Initialize lists to hold sequences and targets\n",
    "sequences = []\n",
    "targets = []\n",
    "padding_length = 50  # Number of timesteps to pad at the end\n",
    "\n",
    "# --------padding with LOCF---------\n",
    "for _, group in data_set.groupby('exp_no'):\n",
    "    # Only select the rows with the relevant columns\n",
    "    data = group[features].values\n",
    "    target_data = group[target_column].values\n",
    "    \n",
    "    # If there is data to pad\n",
    "    if len(data) > 0:\n",
    "        # Pad the end of the dataset with the last value for features\n",
    "        pad_feature = np.repeat(data[-1, :][np.newaxis, :], padding_length, axis=0)\n",
    "        data = np.vstack((data, pad_feature))\n",
    "        \n",
    "        # Pad the end of the dataset with the last value for targets\n",
    "        pad_target = np.repeat(target_data[-1], padding_length)\n",
    "        target_data = np.concatenate((target_data, pad_target))\n",
    "\n",
    "    # Create sequences\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        # Extract the sequence of features and the corresponding target\n",
    "        sequence = data[i:(i + sequence_length)]\n",
    "        target = target_data[i + sequence_length - 1]  # Target aligned with the end of the sequence\n",
    "        \n",
    "        sequences.append(sequence)\n",
    "        targets.append(target)\n",
    "\n",
    "# --------padding with LOCF---------\n",
    "\n",
    "# ---------padding----------\n",
    "\n",
    "# # Group by 'exp_no' and create sequences for each group\n",
    "# for _, group in data_set.groupby('exp_no'):\n",
    "#     # Only select the rows with the relevant columns\n",
    "#     data = group[features].values\n",
    "#     target_data = group[target_column].values\n",
    "    \n",
    "#     # Pad the end of the dataset with zeros for features\n",
    "#     pad_feature = np.zeros((padding_length, len(features)))\n",
    "#     data = np.vstack((data, pad_feature))\n",
    "    \n",
    "#     # Optionally, pad the end of the dataset with zeros or a specific value for targets\n",
    "#     pad_target = np.zeros(padding_length)\n",
    "#     target_data = np.concatenate((target_data, pad_target))\n",
    "\n",
    "#     # Create sequences\n",
    "#     for i in range(len(data) - sequence_length):\n",
    "#         # Extract the sequence of features and the corresponding target\n",
    "#         sequence = data[i:(i + sequence_length)]\n",
    "#         target = target_data[i + sequence_length - 1]  # Target aligned with the end of the sequence\n",
    "        \n",
    "#         sequences.append(sequence)\n",
    "#         targets.append(target)\n",
    "\n",
    "\n",
    "# ---------padding----------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------no padding----------\n",
    "\n",
    "\n",
    "# # Group by 'exp_no' and create sequences for each group\n",
    "# for _, group in data_set.groupby('exp_no'):\n",
    "#     # Only select the rows with the relevant columns\n",
    "#     data = group[features].values\n",
    "#     target_data = group[target_column].values\n",
    "    \n",
    "#     # Create sequences\n",
    "#     for i in range(len(group) - sequence_length):\n",
    "#         # Extract the sequence of features and the corresponding target\n",
    "#         sequence = data[i:(i + sequence_length)]\n",
    "#         target = target_data[i + sequence_length]  # Target is the next record\n",
    "        \n",
    "#         sequences.append(sequence)\n",
    "#         targets.append(target)\n",
    "\n",
    "\n",
    "# ---------no padding----------\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "sequences_np = np.array(sequences)\n",
    "targets_np = np.array(targets)\n",
    "\n",
    "sequences_train, sequences_test, targets_train, targets_test = train_test_split(\n",
    "    sequences_np, targets_np, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Reshape, fit, and transform the training data\n",
    "n_samples_train, sequence_length, n_features = sequences_train.shape\n",
    "sequences_train_reshaped = sequences_train.reshape(-1, n_features)\n",
    "scaler.fit(sequences_train_reshaped)  # Fit only on training data\n",
    "sequences_train_scaled = scaler.transform(sequences_train_reshaped).reshape(n_samples_train, sequence_length, n_features)\n",
    "\n",
    "# Transform the testing data\n",
    "n_samples_test, _, _ = sequences_test.shape\n",
    "sequences_test_reshaped = sequences_test.reshape(-1, n_features)\n",
    "sequences_test_scaled = scaler.transform(sequences_test_reshaped).reshape(n_samples_test, sequence_length, n_features)\n",
    "\n",
    "# Convert numpy arrays to float32 before converting to PyTorch tensors\n",
    "sequences_np = sequences_np.astype(np.float32)\n",
    "targets_np = targets_np.astype(np.float32)\n",
    "\n",
    "train_sequences_tensor = torch.tensor(sequences_train_scaled, dtype=torch.float32)\n",
    "test_sequences_tensor = torch.tensor(sequences_test_scaled, dtype=torch.float32)\n",
    "\n",
    "train_targets_tensor = torch.tensor(targets_train, dtype=torch.float32)\n",
    "test_targets_tensor = torch.tensor(targets_test, dtype=torch.float32)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_sequences_tensor, train_targets_tensor)\n",
    "test_dataset = TensorDataset(test_sequences_tensor, test_targets_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "# batch_size = batch_size  # You can adjust this based on your memory constraints\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        out, _ = self.lstm(x, (h0,c0))  \n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "checkpoint = torch.load('checkpoints/checkpoint_epoch_5_20240410-102415.pt', map_location=torch.device('cpu'))\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.027634603832432592\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "model.eval()  # Ensure the model is in evaluation mode\n",
    "model.to(device)  # Move the model to the device\n",
    "\n",
    "criterion = nn.MSELoss()  # For regression tasks\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "training_losses = []\n",
    "validation_rmses = []\n",
    "\n",
    "total_val_loss = 0\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for sequences_batch, targets_batch in test_loader:\n",
    "        sequences_batch = sequences_batch.to(device)\n",
    "        targets_batch = targets_batch.to(device).unsqueeze(-1)\n",
    "            \n",
    "        outputs = model(sequences_batch)\n",
    "        loss = criterion(outputs, targets_batch)\n",
    "            \n",
    "        total_val_loss += loss.item()\n",
    "        count += 1\n",
    "    \n",
    "avg_val_loss = total_val_loss / count\n",
    "val_rmse = math.sqrt(avg_val_loss)\n",
    "validation_rmses.append(val_rmse)\n",
    "    \n",
    "print(f'Test RMSE: {val_rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 8.92 GB, other allocations: 32.72 MB, max allowed: 9.07 GB). Tried to allocate 139.27 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m test_sequences_tensor \u001b[38;5;241m=\u001b[39m test_sequences_tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m test_sequences_tensor\u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[0;32m----> 3\u001b[0m attr, delta \u001b[38;5;241m=\u001b[39m \u001b[43mig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_sequences_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_convergence_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m attr \u001b[38;5;241m=\u001b[39m attr\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.pyenv/versions/kedro19/lib/python3.11/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/kedro19/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:286\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    274\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m _batch_attribution(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    276\u001b[0m         num_examples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_convergence_delta:\n\u001b[1;32m    296\u001b[0m     start_point, end_point \u001b[38;5;241m=\u001b[39m baselines, inputs\n",
      "File \u001b[0;32m~/.pyenv/versions/kedro19/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:328\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    324\u001b[0m     step_sizes, alphas \u001b[38;5;241m=\u001b[39m step_sizes_and_alphas\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# scale features and compute gradients. (batch size is abbreviated as bsz)\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# scaled_features' dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m scaled_features_tpl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43malphas\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(\n\u001b[1;32m    336\u001b[0m     additional_forward_args\n\u001b[1;32m    337\u001b[0m )\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# apply number of steps to additional forward args\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# currently, number of steps is applied only to additional forward arguments\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# that are nd-tensors. It is assumed that the first dimension is\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# the number of batches.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# dim -> (bsz * #steps x additional_forward_args[0].shape[1:], ...)\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/kedro19/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:330\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    324\u001b[0m     step_sizes, alphas \u001b[38;5;241m=\u001b[39m step_sizes_and_alphas\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# scale features and compute gradients. (batch size is abbreviated as bsz)\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# scaled_features' dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[1;32m    328\u001b[0m scaled_features_tpl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    329\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[0;32m--> 330\u001b[0m         \u001b[43m[\u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43malphas\u001b[49m\u001b[43m]\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    331\u001b[0m     )\u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m, baseline \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(inputs, baselines)\n\u001b[1;32m    333\u001b[0m )\n\u001b[1;32m    335\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(\n\u001b[1;32m    336\u001b[0m     additional_forward_args\n\u001b[1;32m    337\u001b[0m )\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# apply number of steps to additional forward args\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# currently, number of steps is applied only to additional forward arguments\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# that are nd-tensors. It is assumed that the first dimension is\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# the number of batches.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# dim -> (bsz * #steps x additional_forward_args[0].shape[1:], ...)\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/kedro19/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:330\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    324\u001b[0m     step_sizes, alphas \u001b[38;5;241m=\u001b[39m step_sizes_and_alphas\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# scale features and compute gradients. (batch size is abbreviated as bsz)\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# scaled_features' dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[1;32m    328\u001b[0m scaled_features_tpl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    329\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[0;32m--> 330\u001b[0m         [baseline \u001b[38;5;241m+\u001b[39m \u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m alphas], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    331\u001b[0m     )\u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m, baseline \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(inputs, baselines)\n\u001b[1;32m    333\u001b[0m )\n\u001b[1;32m    335\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(\n\u001b[1;32m    336\u001b[0m     additional_forward_args\n\u001b[1;32m    337\u001b[0m )\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# apply number of steps to additional forward args\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# currently, number of steps is applied only to additional forward arguments\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# that are nd-tensors. It is assumed that the first dimension is\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# the number of batches.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# dim -> (bsz * #steps x additional_forward_args[0].shape[1:], ...)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 8.92 GB, other allocations: 32.72 MB, max allowed: 9.07 GB). Tried to allocate 139.27 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "test_sequences_tensor = test_sequences_tensor.to(device)\n",
    "test_sequences_tensor.requires_grad_()\n",
    "attr, delta = ig.attribute(test_sequences_tensor,target=1, return_convergence_delta=True)\n",
    "attr = attr.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro19",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
